{
  "sample_order": 4,
  "function": "def sparsesc(L, lambda_, k, opts):\n    tol = opts.get('tol', 1e-8)\n    max_iter = opts.get('max_iter', 500)\n    rho = opts.get('rho', 1.1)\n    mu = opts.get('mu', 1e-4)\n    max_mu = opts.get('max_mu', 1e10)\n    DEBUG = opts.get('DEBUG', 0)\n\n    n = L.shape[0]\n    P = np.zeros((n, n))\n    Q = np.zeros_like(P)\n    Y = np.zeros_like(P)\n\n    for iter_ in range(max_iter):\n        Pk = P.copy()\n        Qk = Q.copy()\n\n        # Update P\n        P = prox_l1(Q - (Y + L) / mu, lambda_ / mu)\n\n        # Update Q\n        temp = (P + Y / mu)\n        temp = (temp + temp.T) / 2\n        Q = project_fantope(temp, k)\n\n        dY = P - Q\n        chgP = np.max(np.abs(Pk - P))\n        chgQ = np.max(np.abs(Qk - Q))\n        chg = max(chgP, chgQ, np.max(np.abs(dY)))\n\n        if DEBUG and (iter_ == 0 or (iter_ + 1) % 10 == 0):\n            obj = np.trace(np.dot(P.T, L)) + lambda_ * np.sum(np.abs(Q))\n            err = np.linalg.norm(dY, 'fro')\n            print(f\"iter {iter_+1}, mu={mu}, obj={obj}, err={err}\")\n\n        if chg < tol:\n            break\n\n        # Dynamic adjustment of rho\n        if np.linalg.norm(dY, 'fro') > 10 * np.linalg.norm(P - Q, 'fro'):\n            rho *= 1.1\n        elif np.linalg.norm(P - Q, 'fro') > 10 * np.linalg.norm(dY, 'fro'):\n            rho /= 1.1\n\n        Y = Y + mu * dY\n        mu = min(rho * mu, max_mu)\n\n    obj = np.trace(np.dot(P.T, L)) + lambda_ * np.sum(np.abs(Q))\n    err = np.linalg.norm(dY, 'fro')\n\n    return P, obj, err, iter_\n\n",
  "score": -999.0
}
