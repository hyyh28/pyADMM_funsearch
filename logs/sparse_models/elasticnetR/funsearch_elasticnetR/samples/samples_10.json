{"sample_order": 10, "function": "def elasticnetR(A, B, lambda1, lambda2, opts):\n    tol = opts.get('tol', 1e-6)\n    max_iter = opts.get('max_iter', 1000)\n    rho = opts.get('rho', 1.1)\n    mu = opts.get('mu', 1e-4)\n    max_mu = opts.get('max_mu', 1e10)\n    DEBUG = opts.get('DEBUG', 0)\n    loss = opts.get('loss', 'l1')\n\n    d, na = A.shape\n    _, nb = B.shape\n\n    X = np.zeros((na, nb))\n    E = np.zeros((d, nb))\n    Z = np.zeros_like(X)\n    Y1 = np.zeros_like(E)\n    Y2 = np.zeros_like(X)\n\n    AtB = A.T @ B\n    I = np.eye(na)\n    invAtAI = np.linalg.inv(A.T @ A + I)\n\n    for iter in range(1, max_iter + 1):\n        Xk, Ek, Zk = X.copy(), E.copy(), Z.copy()\n\n        # First super block {X, E}\n        X = prox_elasticnet(Z - Y2 / mu, lambda1 / mu, lambda2 / mu)\n        if loss == 'l1':\n            E = prox_l1(B - A @ Z - Y1 / mu, 1 / mu)\n        elif loss == 'l2':\n            E = mu * (B - A @ Z - Y1 / mu) / (1 + mu)\n        else:\n            raise ValueError('Unsupported loss function')\n\n        # Second super block {Z}\n        Z = invAtAI @ (-A.T @ (Y1 / mu + E) + AtB + Y2 / mu + X)\n\n        # Compute residuals and errors\n        dY1 = A @ Z + E - B\n        dY2 = X - Z\n        chgX = np.max(np.abs(Xk - X))\n        chgE = np.max(np.abs(Ek - E))\n        chgZ = np.max(np.abs(Zk - Z))\n        chg = max(chgX, chgE, chgZ, np.max(np.abs(dY1)), np.max(np.abs(dY2)))\n\n        if DEBUG and (iter == 1 or iter % 10 == 0):\n            obj = comp_loss(E, loss) + lambda1 * np.linalg.norm(X, 1) + lambda2 * np.linalg.norm(X, 'fro') ** 2\n            err = np.sqrt(np.linalg.norm(dY1, 'fro') ** 2 + np.linalg.norm(dY2, 'fro') ** 2)\n            print(f\"iter {iter}, mu={mu}, obj={obj}, err={err}\")\n\n        if chg < tol:\n            break\n\n        # Update rho dynamically\n        rho_update_factor = 1.01\n        rho *= rho_update_factor\n        mu = min(rho * mu, max_mu)\n\n        Y1 += mu * dY1\n        Y2 += mu * dY2\n\n    obj = comp_loss(E, loss) + lambda1 * np.linalg.norm(X, 1) + lambda2 * np.linalg.norm(X, 'fro') ** 2\n    err = np.sqrt(np.linalg.norm(dY1, 'fro') ** 2 + np.linalg.norm(dY2, 'fro') ** 2)\n    \n    return X, E, obj, err, iter\n\n", "score": -64.0}