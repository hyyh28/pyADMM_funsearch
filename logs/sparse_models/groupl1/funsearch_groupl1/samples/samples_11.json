{
  "sample_order": 11,
  "function": "def groupl1_admm(A, B, G, opts):\n    tol = opts.get('tol', 1e-6)\n    max_iter = opts.get('max_iter', 1000)\n    rho = opts.get('rho', 1.1)\n    mu = opts.get('mu', 1e-4)\n    max_mu = opts.get('max_mu', 1e10)\n    DEBUG = opts.get('DEBUG', 0)\n    \n    d, na = A.shape\n    _, nb = B.shape\n\n    X = np.zeros((na, nb))\n    Z = np.zeros_like(X)\n    Y1 = np.zeros((d, nb))\n    Y2 = np.zeros_like(X)\n\n    AtB = A.T @ B\n    I = np.eye(na)\n    invAtAI = np.linalg.inv(A.T @ A + I) @ I\n\n    for iter in range(1, max_iter + 1):\n        Xk = X.copy()\n        Zk = Z.copy()\n        \n        # Update X\n        X = np.array([prox_gl1(Z[:, i] - Y2[:, i] / mu, G, 1 / mu) for i in range(nb)]).T\n        \n        # Update Z\n        Z = invAtAI @ (-A.T @ Y1 / mu + AtB + Y2 / mu + X)\n        \n        dY1 = A @ Z - B\n        dY2 = X - Z\n        \n        chgX = np.max(np.abs(Xk - X))\n        chgZ = np.max(np.abs(Zk - Z))\n        chg = max([chgX, chgZ, np.max(np.abs(dY1)), np.max(np.abs(dY2))])\n        \n        if DEBUG and (iter == 1 or iter % 10 == 0):\n            obj = sum(np.linalg.norm(X[g], axis=1).sum() for g in G)\n            err = np.sqrt(np.linalg.norm(dY1, 'fro')**2 + np.linalg.norm(dY2, 'fro')**2)\n            print(f'iter {iter}, mu={mu}, rho={rho}, obj={obj}, err={err}')\n        \n        if chg < tol:\n            break\n        \n        # Update dual variables\n        Y1 = Y1 + mu * dY1\n        Y2 = Y2 + mu * dY2\n        \n        # Update penalty parameter rho dynamically\n        rho_update_factor = 1.01  # Example factor for updating rho\n        rho = min(rho * rho_update_factor, max_mu)\n        \n        # Update mu\n        mu = min(rho * mu, max_mu)\n    \n    obj = sum(np.linalg.norm(X[g], axis=1).sum() for g in G)\n    err = np.sqrt(np.linalg.norm(dY1, 'fro')**2 + np.linalg.norm(dY2, 'fro')**2)\n    \n    return X, obj, err, iter\n\n",
  "score": -56.0
}
